{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Eventhubsend+receive.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNxG1oOZ93zdhYmHpIIQ1Gv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anuthereaper/PythonLibrary/blob/main/Eventhubsend%2Breceive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_36bQre48V0n"
      },
      "source": [
        "pip install azure-eventhub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M-E43kupB-M"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VRcE3G4YVBC"
      },
      "source": [
        "import time\n",
        "import os\n",
        "from azure.eventhub import EventHubProducerClient, EventData\n",
        "from azure.eventhub.exceptions import EventHubError\n",
        "\n",
        "CONNECTION_STR = \"Endpoint=sb://\"\n",
        "EVENTHUB_NAME = \"xxxxxxxxxx\"\n",
        "\n",
        "def send_event_data_batch(producer,message):\n",
        "    # Without specifying partition_id or partition_key\n",
        "    # the events will be distributed to available partitions via round-robin.\n",
        "    event_data_batch = producer.create_batch()\n",
        "    event_data_batch.add(EventData(message))\n",
        "    producer.send_batch(event_data_batch)\n",
        "\n",
        "\n",
        "def send_event_data_batch_with_limited_size(producer,max_size):\n",
        "    # Without specifying partition_id or partition_key\n",
        "    # the events will be distributed to available partitions via round-robin.\n",
        "    event_data_batch_with_limited_size = producer.create_batch(max_size_in_bytes=max_size)\n",
        "    i = 1\n",
        "    while True:\n",
        "        try:\n",
        "            event_data_batch_with_limited_size.add(EventData('Message inside EventBatchData limited by size ' + str(i)))\n",
        "            i = i + 1\n",
        "        except ValueError:\n",
        "            # EventDataBatch object reaches max_size.\n",
        "            # New EventDataBatch object can be created here to send more data.\n",
        "            break\n",
        "\n",
        "    producer.send_batch(event_data_batch_with_limited_size)\n",
        "\n",
        "def send_event_data_batch_with_partition_key(producer,message,key):\n",
        "    # Specifying partition_key.\n",
        "    event_data_batch_with_partition_key = producer.create_batch(partition_key=key)\n",
        "    event_data_batch_with_partition_key.add(EventData(message))\n",
        "\n",
        "    producer.send_batch(event_data_batch_with_partition_key)\n",
        "\n",
        "def send_event_data_batch_with_partition_id(producer,message,id):\n",
        "    # Specifying partition_id.\n",
        "    event_data_batch_with_partition_id = producer.create_batch(partition_id=id)\n",
        "    event_data_batch_with_partition_id.add(EventData(message))\n",
        "\n",
        "    producer.send_batch(event_data_batch_with_partition_id)\n",
        "\n",
        "def send_event_data_batch_with_properties(producer,message):\n",
        "    event_data_batch = producer.create_batch()\n",
        "    event_data = EventData(message)\n",
        "    event_data.properties = {'prop_key': 'prop_value'}\n",
        "    event_data_batch.add(event_data)\n",
        "    producer.send_batch(event_data_batch)\n",
        "\n",
        "def send_event_data_list(producer,no_of_events):\n",
        "    # If you know beforehand that the list of events you have will not exceed the\n",
        "    # size limits, you can use the `send_batch()` api directly without creating an EventDataBatch\n",
        "\n",
        "    # Without specifying partition_id or partition_key\n",
        "    # the events will be distributed to available partitions via round-robin.\n",
        "\n",
        "    event_data_list = [EventData('Event Data {} in list'.format(i)) for i in range(no_of_events)]\n",
        "    try:\n",
        "        producer.send_batch(event_data_list)\n",
        "    except ValueError:  # Size exceeds limit. This shouldn't happen if you make sure before hand.\n",
        "        print(\"Size of the event data list exceeds the size limit of a single send\")\n",
        "    except EventHubError as eh_err:\n",
        "        print(\"Sending error: \", eh_err)\n",
        "\n",
        "producer = EventHubProducerClient.from_connection_string(\n",
        "    conn_str=CONNECTION_STR,\n",
        "    eventhub_name=EVENTHUB_NAME\n",
        ")\n",
        "\n",
        "start_time = time.time()\n",
        "with producer:\n",
        "    send_event_data_batch(producer,'Single message')\n",
        "    send_event_data_batch_with_limited_size(producer,1000)\n",
        "    send_event_data_batch_with_partition_key(producer,'Message will be sent to a partition determined by the partition key','pkey')\n",
        "    send_event_data_batch_with_partition_id(producer,'Message will be sent to target-id partition',0)\n",
        "    send_event_data_batch_with_properties(producer,'Message with properties')\n",
        "    send_event_data_list(producer,10)\n",
        "\n",
        "print(\"Send messages in {} seconds.\".format(time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mpZ0Cod9uDw"
      },
      "source": [
        "# Event hub receiver\n",
        "import os\n",
        "from azure.eventhub import EventHubConsumerClient\n",
        "\n",
        "CONNECTION_STR = \"Endpoint=sb://\"\n",
        "EVENTHUB_NAME = \"anueventhub\"\n",
        "\n",
        "def on_event(partition_context, event):\n",
        "    # Put your code here.\n",
        "    # If the operation is i/o intensive, multi-thread will have better performance.\n",
        "#    print(\"Received event from partition: {}.\".format(partition_context.partition_id))\n",
        "    print(\"Received the event: {} from the partition with ID: {}\".format(event.body_as_str(encoding='UTF-8'), partition_context.partition_id))\n",
        "\n",
        "\n",
        "def on_partition_initialize(partition_context):\n",
        "    # Put your code here.\n",
        "    print(\"Partition: {} has been initialized.\".format(partition_context.partition_id))\n",
        "\n",
        "\n",
        "def on_partition_close(partition_context, reason):\n",
        "    # Put your code here.\n",
        "    print(\"Partition: {} has been closed, reason for closing: {}.\".format(\n",
        "        partition_context.partition_id,\n",
        "        reason\n",
        "    ))\n",
        "\n",
        "\n",
        "def on_error(partition_context, error):\n",
        "    # Put your code here. partition_context can be None in the on_error callback.\n",
        "    if partition_context:\n",
        "        print(\"An exception: {} occurred during receiving from Partition: {}.\".format(\n",
        "            partition_context.partition_id,\n",
        "            error\n",
        "        ))\n",
        "    else:\n",
        "        print(\"An exception: {} occurred during the load balance process.\".format(error))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    consumer_client = EventHubConsumerClient.from_connection_string(\n",
        "        conn_str=CONNECTION_STR,\n",
        "        consumer_group='$Default',\n",
        "        eventhub_name=EVENTHUB_NAME,\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        with consumer_client:\n",
        "            consumer_client.receive(\n",
        "                on_event=on_event,\n",
        "                on_partition_initialize=on_partition_initialize,\n",
        "                on_partition_close=on_partition_close,\n",
        "                on_error=on_error,\n",
        "                starting_position=\"-1\",  # \"-1\" is from the beginning of the partition.\n",
        "            )\n",
        "    except KeyboardInterrupt:\n",
        "        print('Stopped receiving.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUgd3vveZIFA"
      },
      "source": [
        "pip install names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziFy-cAZVBSU"
      },
      "source": [
        "# SEND MULTIPLE MESSAGES TO EVENT HUB\n",
        "import time\n",
        "import os\n",
        "from azure.eventhub import EventHubProducerClient, EventData\n",
        "from azure.eventhub.exceptions import EventHubError\n",
        "from random import randrange\n",
        "import random\n",
        "import names\n",
        "from datetime import datetime\n",
        "from datetime import timedelta\n",
        "import uuid\n",
        "import json\n",
        "\n",
        "CONNECTION_STR = \"Endpoint=sb://xxxxxxxxxx.servicebus.windows.net/;SharedAccessKeyName=master;SharedAccessKey=xxxxxxxx\"\n",
        "EVENTHUB_NAME = \"anueventhub\"\n",
        "\n",
        "Number_of_docs = 50\n",
        "d1 = datetime.strptime('1/1/2008 1:30 PM', '%m/%d/%Y %I:%M %p')\n",
        "d2 = datetime.strptime('1/1/2009 4:50 AM', '%m/%d/%Y %I:%M %p')\n",
        "\n",
        "def send_event_data_batch(producer,message):\n",
        "    # Without specifying partition_id or partition_key\n",
        "    # the events will be distributed to available partitions via round-robin.\n",
        "    event_data_batch = producer.create_batch()\n",
        "    event_data_batch.add(EventData(message))\n",
        "    producer.send_batch(event_data_batch)\n",
        "\n",
        "\n",
        "def send_event_data_batch_with_limited_size(producer,max_size):\n",
        "    # Without specifying partition_id or partition_key\n",
        "    # the events will be distributed to available partitions via round-robin.\n",
        "    event_data_batch_with_limited_size = producer.create_batch(max_size_in_bytes=max_size)\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            event_data_batch_with_limited_size.add(EventData('Message inside EventBatchData'))\n",
        "        except ValueError:\n",
        "            # EventDataBatch object reaches max_size.\n",
        "            # New EventDataBatch object can be created here to send more data.\n",
        "            break\n",
        "\n",
        "    producer.send_batch(event_data_batch_with_limited_size)\n",
        "\n",
        "\n",
        "def send_event_data_batch_with_partition_key(producer,message,key):\n",
        "    # Specifying partition_key.\n",
        "    event_data_batch_with_partition_key = producer.create_batch(partition_key=key)\n",
        "    event_data_batch_with_partition_key.add(EventData(message))\n",
        "\n",
        "    producer.send_batch(event_data_batch_with_partition_key)\n",
        "\n",
        "def send_event_data_batch_with_partition_id(producer,message,id):\n",
        "    # Specifying partition_id.\n",
        "    event_data_batch_with_partition_id = producer.create_batch(partition_id=id)\n",
        "    event_data_batch_with_partition_id.add(EventData(message))\n",
        "\n",
        "    producer.send_batch(event_data_batch_with_partition_id)\n",
        "\n",
        "def send_event_data_batch_with_properties(producer,message):\n",
        "    event_data_batch = producer.create_batch()\n",
        "    event_data = EventData(message)\n",
        "    event_data.properties = {'prop_key': 'prop_value'}\n",
        "    event_data_batch.add(event_data)\n",
        "    producer.send_batch(event_data_batch)\n",
        "\n",
        "def send_event_data_list(producer):\n",
        "    # If you know beforehand that the list of events you have will not exceed the\n",
        "    # size limits, you can use the `send_batch()` api directly without creating an EventDataBatch\n",
        "\n",
        "    # Without specifying partition_id or partition_key\n",
        "    # the events will be distributed to available partitions via round-robin.\n",
        "\n",
        "    event_data_list = [EventData('Event Data {}'.format(i)) for i in range(10)]\n",
        "    try:\n",
        "        producer.send_batch(event_data_list)\n",
        "    except ValueError:  # Size exceeds limit. This shouldn't happen if you make sure before hand.\n",
        "        print(\"Size of the event data list exceeds the size limit of a single send\")\n",
        "    except EventHubError as eh_err:\n",
        "        print(\"Sending error: \", eh_err)\n",
        "\n",
        "def random_date(start, end):\n",
        "    \"\"\"\n",
        "    This function will return a random datetime between two datetime \n",
        "    objects.\n",
        "    \"\"\"\n",
        "    delta = end - start\n",
        "    int_delta = (delta.days * 24 * 60 * 60) + delta.seconds\n",
        "    random_second = randrange(int_delta)\n",
        "    return start + timedelta(seconds=random_second)\n",
        "\n",
        "def Create_Record(item_id):\n",
        "    doc_body = {'id' : str(uuid.uuid4()),\n",
        "            'employee_id' : str(id),\n",
        "            'first_name' : names.get_first_name(),\n",
        "            'last_name' : names.get_last_name(),\n",
        "            'regn_no' : 'TEST000000001',\n",
        "            'start_date' : str(random_date(d1,d2)),\n",
        "            'salary' : str(random.randint(12000, 2000000)),\n",
        "            'inserted_at' : str(datetime.now())\n",
        "            }\n",
        "    json_object = json.dumps(doc_body, indent = 4) \n",
        "#   print(json_object)\n",
        "    return bytes(json_object,'utf-8')\n",
        "\n",
        "producer = EventHubProducerClient.from_connection_string(\n",
        "    conn_str=CONNECTION_STR,\n",
        "    eventhub_name=EVENTHUB_NAME\n",
        ")\n",
        "\n",
        "#start_time = time.time()\n",
        "starttime = datetime.utcnow()\n",
        "print(\"Starting ingestion: \", starttime.strftime(\"%Y-%m-%d %H:%M:%S.%f\"))\n",
        "with producer:\n",
        "    for i in range(Number_of_docs):\n",
        "         start_time = time.time()\n",
        "         message = Create_Record(i)\n",
        "         send_event_data_batch(producer,message)\n",
        "         if (i+1)%100 == 0 or (i == Number_of_docs-1):\n",
        "            print(str(i+1) + \" documents completed\")\n",
        "    #        send_event_data_batch_with_limited_size(producer)\n",
        "    #       loop = 'y'\n",
        "    #        while loop == 'y':\n",
        "    #            if ((time.time() - start_time) > 1):\n",
        "    #                loop = 'n'\n",
        "    #            else:\n",
        "    #                sleep(0.1)\n",
        "endtime = datetime.utcnow()\n",
        "print(\"\\nrun_sample done :\" + endtime.strftime(\"%Y-%m-%d %H:%M:%S.%f\"))\n",
        "print(\"Time taken :\" + str(endtime-starttime))\n",
        "print(\"Number of messages :\" + str(Number_of_docs))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}